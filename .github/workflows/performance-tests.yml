name: Performance Tests

on:
  workflow_run:
    workflows: [ "Portfolio CI" ]
    types: [ completed ]
    branches: [ master ]

env:
  APP_PORT: '9090'
  JMETER_VERSION: '5.6.2'
  THREADS_COUNT: '10'
  RAMP_UP_PERIOD: '10'
  TEST_DURATION: '60'
  APP_STARTUP_TIMEOUT: '180'
  ERROR_THRESHOLD: '5'

permissions:
  actions: read
  checks: write

jobs:
  performance-tests:
    runs-on: ubuntu-latest
    if: github.event.workflow_run.conclusion == 'success'

    steps:
      - name: Debug workflow information
        run: |
          echo "Workflow conclusion: ${{ github.event.workflow_run.conclusion }}"
          echo "Workflow status: ${{ github.event.workflow_run.status }}"
          echo "Workflow head sha: ${{ github.event.workflow_run.head_sha }}"

      - uses: actions/checkout@v3

      - name: Create necessary directories
        run: |
          mkdir -p backend/target
          mkdir -p jmeter-results

      - name: Download build artifacts
        uses: dawidd6/action-download-artifact@v2
        with:
          name: build-artifacts-${{ github.event.workflow_run.head_sha }}
          workflow: Portfolio CI
          path: backend/target/
          workflow_conclusion: success
          github_token: ${{ secrets.GITHUB_TOKEN }}

      - name: Verify application files
        run: |
          if ! ls backend/target/*.jar >/dev/null 2>&1; then
            echo "Error: No JAR files found in backend/target/"
            exit 1
          fi

      - name: Install dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y curl wget unzip netcat-openbsd

      - name: Setup JMeter
        run: |
          mkdir -p jmeter
          cd jmeter
          wget https://archive.apache.org/dist/jmeter/binaries/apache-jmeter-${{ env.JMETER_VERSION }}.tgz || \
          wget https://downloads.apache.org/jmeter/binaries/apache-jmeter-${{ env.JMETER_VERSION }}.tgz || \
          curl -L -O https://archive.apache.org/dist/jmeter/binaries/apache-jmeter-${{ env.JMETER_VERSION }}.tgz
          
          if [ ! -f apache-jmeter-${{ env.JMETER_VERSION }}.tgz ]; then
            echo "Failed to download JMeter"
            exit 1
          fi
          
          tar -xzf apache-jmeter-${{ env.JMETER_VERSION }}.tgz
          echo "JMETER_HOME=$PWD/apache-jmeter-${{ env.JMETER_VERSION }}" >> $GITHUB_ENV
          echo "$PWD/apache-jmeter-${{ env.JMETER_VERSION }}/bin" >> $GITHUB_PATH

      - name: Start Spring Boot Application
        run: |
          java -jar backend/target/*.jar --server.port=${{ env.APP_PORT }} &
          echo "Waiting for application to start..."
          if ! timeout ${{ env.APP_STARTUP_TIMEOUT }} bash -c 'while ! nc -z localhost ${{ env.APP_PORT }}; do sleep 2; done'; then
            echo "Failed to start application within timeout"
            exit 1
          fi

      - name: Run JMeter Tests
        run: |
          if [ ! -f "backend/src/test/jmeter/test-plan.jmx" ]; then
            echo "Test plan file not found!"
            exit 1
          fi
          
          jmeter -n \
            -t backend/src/test/jmeter/test-plan.jmx \
            -l jmeter-results/results.jtl \
            -j jmeter-results/jmeter.log \
            -e -o jmeter-results/dashboard \
            -Jhost=localhost \
            -Jport=${{ env.APP_PORT }} \
            -Jprotocol=http \
            -Jthreads=${{ env.THREADS_COUNT }} \
            -Jrampup=${{ env.RAMP_UP_PERIOD }} \
            -Jduration=${{ env.TEST_DURATION }}

      - name: Generate Report Summary
        if: always()
        run: |
          echo "# Performance Test Summary" > jmeter-results/summary.txt
          echo "Test Duration: ${{ env.TEST_DURATION }} seconds" >> jmeter-results/summary.txt
          echo "Number of Threads: ${{ env.THREADS_COUNT }}" >> jmeter-results/summary.txt
          
          if [ -f "jmeter-results/results.jtl" ]; then
            # Calculate statistics
            awk -F',' '
              NR>1 {
                total++
                if($4>=400) errors++
                sum_rt+=$2
                if($2>max_rt) max_rt=$2
              } 
              END {
                error_rate = (errors/total)*100
                avg_rt = sum_rt/total
                print "Total Requests: " total
                print "Error Rate: " error_rate "%"
                print "Average Response Time: " avg_rt " ms"
                print "Max Response Time: " max_rt " ms"
              }' jmeter-results/results.jtl >> jmeter-results/summary.txt
          fi

      - name: Upload Performance Results
        uses: actions/upload-artifact@v3
        if: always()
        with:
          name: performance-results-${{ github.event.workflow_run.head_sha }}
          path: |
            jmeter-results/
            jmeter-results/dashboard/
            jmeter-results/jmeter.log
            jmeter-results/summary.txt
          retention-days: 7

      - name: Check Test Results
        if: always()
        run: |
          if [ -f "jmeter-results/results.jtl" ]; then
            error_count=$(awk -F',' 'NR>1 && $4>=400 {err++} END {print err}' jmeter-results/results.jtl)
            total_count=$(awk -F',' 'NR>1 {total++} END {print total}' jmeter-results/results.jtl)
            error_rate=$(( error_count * 100 / total_count ))
          
            if [ $error_rate -gt ${{ env.ERROR_THRESHOLD }} ]; then
              echo "Performance tests failed: Error rate ${error_rate}% exceeds threshold of ${{ env.ERROR_THRESHOLD }}%"
              exit 1
            fi
          
            echo "Performance tests passed: Error rate ${error_rate}% is within acceptable threshold"
          else
            echo "No test results found"
            exit 1
          fi

      - name: Stop Spring Boot Application
        if: always()
        run: pkill -f '.jar' || true